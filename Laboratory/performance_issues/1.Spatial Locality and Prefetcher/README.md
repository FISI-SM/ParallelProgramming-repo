
# Caso 1: Localidad Espacial y Prefetcher

## Contexto
En arquitecturas modernas de computadoras, la jerarqu√≠a de memoria juega un papel fundamental en el rendimiento. Cuando accedemos a datos en la memoria, idealmente queremos que est√©n presentes en la cach√© para evitar latencias elevadas. Esto es posible gracias al principio de **localidad espacial**, y a mecanismos como el **prefetcher**, que intenta anticiparse a los accesos cargando datos contiguos en la cach√©.

## Versi√≥n con bajo rendimiento ‚ùå
En esta implementaci√≥n, se accede a un vector de 100 MB de forma **aleatoria**. Esto rompe la localidad espacial porque los accesos a memoria no siguen un patr√≥n predecible ni secuencial. Como resultado:
- El **prefetcher** no puede predecir los accesos.
- Se producen muchas **fallas de cach√© (cache misses)**.
- El rendimiento del programa se ve seriamente afectado.

Este patr√≥n es t√≠pico de algoritmos que manipulan estructuras dispersas o no secuenciales, y si no se maneja adecuadamente, puede convertirse en un cuello de botella para la paralelizaci√≥n eficiente.

## Versi√≥n optimizada ‚úÖ
La versi√≥n mejorada tambi√©n genera n√∫meros aleatorios, pero **accede secuencialmente** al arreglo (`vec[i]` en vez de `vec[pos]`). Esto aprovecha:
- La **localidad espacial**: los elementos contiguos son cargados en bloques a la cach√©.
- El **prefetcher**, que trabaja de forma m√°s efectiva al detectar el patr√≥n secuencial.

Aunque sigue usando n√∫meros aleatorios para mantener similitud con la l√≥gica anterior, el acceso a memoria es mucho m√°s eficiente.

## Relaci√≥n con Programaci√≥n Paralela üîó
En programaci√≥n paralela, el acceso eficiente a la memoria compartida entre hilos (threads) o procesos es esencial para la escalabilidad. Incluso con m√∫ltiples n√∫cleos, si cada hilo accede a memoria de manera ineficiente (aleatoriamente o sin considerar la jerarqu√≠a de cach√©), los beneficios del paralelismo se ven anulados.

Este ejemplo refuerza un principio clave de Peter Pacheco: **el paralelismo efectivo depende tanto de la computaci√≥n como del movimiento de datos**. Acceder eficientemente a la memoria es tan importante como dividir bien el trabajo entre hilos.
